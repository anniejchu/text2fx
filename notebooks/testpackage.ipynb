{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7eacda86-bb9e-4217-9c1c-913500c52f88",
   "metadata": {},
   "source": [
    "## Text2FX demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c103f115-e5a6-436b-81bf-84acaf794cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import text2fx\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a97d8c2-6f68-4fef-90c1-e5a1ca838f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from text2fx.apply import main as apply \n",
    "from text2fx.applybatch import main as applybatch\n",
    "from text2fx.process_file_from_params import apply_fx_to_sig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73edaf8-3036-4c1b-8f57-100b44530887",
   "metadata": {},
   "source": [
    "## Inference: Text2FX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3c2fde-07eb-4bfc-92bc-33c659090d4a",
   "metadata": {},
   "source": [
    "### For a single (audio_file, target_text_descriptor) pair, use apply()\n",
    "it will return x,y,z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0aaa9b67-2d6d-493a-af76-89f23f4a6d0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0maudio_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudiotools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio_signal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAudioSignal\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfx_chain\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtext_target\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mexport_dir\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlearning_rate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mparams_init_type\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'random'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mroll_amt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_iters\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m600\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcriterion\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cosine-sim'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'ms_clap'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdetailed_log\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
       "\u001b[0;31mFile:\u001b[0m      ~/research/text2fx/text2fx/apply.py\n",
       "\u001b[0;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "apply?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc82e041-9744-4aff-8f5d-d1fe1b41a717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text2fx on full sig\n",
      "1. processing input ... /home/annie/research/text2fx/assets/multistem_examples/10s/bass.wav\n",
      "2. created channel from ['eq', 'reverb'] ... [<dasp_pytorch.modules.ParametricEQ object at 0x7fa12ad101f0>, <dasp_pytorch.modules.NoiseShapedReverb object at 0x7fa12ad10070>]\n",
      "3. applying text2fx ..., target warm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step: 50/50, loss: 0.778: 100%|██████████████████████████████████████| 50/50 [00:16<00:00,  3.08it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ParametricEQ': {'low_shelf_gain_db': tensor([-1.3869]),\n",
       "  'low_shelf_cutoff_freq': tensor([1142.6503]),\n",
       "  'low_shelf_q_factor': tensor([0.7847]),\n",
       "  'band0_gain_db': tensor([8.3911]),\n",
       "  'band0_cutoff_freq': tensor([295.0082]),\n",
       "  'band0_q_factor': tensor([2.2558]),\n",
       "  'band1_gain_db': tensor([11.3244]),\n",
       "  'band1_cutoff_freq': tensor([7086.5928]),\n",
       "  'band1_q_factor': tensor([1.2868]),\n",
       "  'band2_gain_db': tensor([4.5187]),\n",
       "  'band2_cutoff_freq': tensor([10967.1631]),\n",
       "  'band2_q_factor': tensor([3.0410]),\n",
       "  'band3_gain_db': tensor([7.2473]),\n",
       "  'band3_cutoff_freq': tensor([18863.2363]),\n",
       "  'band3_q_factor': tensor([3.1242]),\n",
       "  'high_shelf_gain_db': tensor([7.2540]),\n",
       "  'high_shelf_cutoff_freq': tensor([11817.3945]),\n",
       "  'high_shelf_q_factor': tensor([0.6948])},\n",
       " 'NoiseShapedReverb': {'band0_gain': tensor([0.1164]),\n",
       "  'band1_gain': tensor([0.7600]),\n",
       "  'band2_gain': tensor([0.2692]),\n",
       "  'band3_gain': tensor([0.6566]),\n",
       "  'band4_gain': tensor([0.3524]),\n",
       "  'band5_gain': tensor([0.3006]),\n",
       "  'band6_gain': tensor([0.6813]),\n",
       "  'band7_gain': tensor([0.7060]),\n",
       "  'band8_gain': tensor([0.6465]),\n",
       "  'band9_gain': tensor([0.3263]),\n",
       "  'band10_gain': tensor([0.6599]),\n",
       "  'band11_gain': tensor([0.2390]),\n",
       "  'band0_decay': tensor([0.2891]),\n",
       "  'band1_decay': tensor([0.3804]),\n",
       "  'band2_decay': tensor([0.1899]),\n",
       "  'band3_decay': tensor([0.4513]),\n",
       "  'band4_decay': tensor([0.5095]),\n",
       "  'band5_decay': tensor([0.4168]),\n",
       "  'band6_decay': tensor([0.5124]),\n",
       "  'band7_decay': tensor([0.6625]),\n",
       "  'band8_decay': tensor([0.5235]),\n",
       "  'band9_decay': tensor([0.3047]),\n",
       "  'band10_decay': tensor([0.2641]),\n",
       "  'band11_decay': tensor([0.4794]),\n",
       "  'mix': tensor([0.4355])}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_path = Path(\"/home/annie/research/text2fx/assets/multistem_examples/10s/bass.wav\")\n",
    "export_dir = Path(\"/home/annie/research/text2fx/experiments/2025-02-17/testpackage/\")\n",
    "\n",
    "apply(audio_path, \n",
    "      ['eq', 'reverb'], \n",
    "      \"warm\", \n",
    "      n_iters=50,\n",
    "      detailed_log=False, #toggle True if you want to export optimized FXparams + audio every 100 iters\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5685d6df-a5b0-4f8a-99fb-6ec11502cd53",
   "metadata": {},
   "source": [
    "### to reapply sig, use applyfx_to_sig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d405c728-5c14-4c3e-a2d1-fa1081542617",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADD IN EXAMPLE OF CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f501273b-47ef-475c-91bf-8bb755bd0c40",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Plotting Freq Responses via text2fx.core_plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759efa70-c03f-42cb-9b10-475506655bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing detailed_log = False, just in_sig and final_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a641cc-c4dd-43c7-ad36-96db7a3b7f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing detailed_log = True --  in_sig, every 100_iters, final_sig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdda25ed-8db3-4fe9-9d8a-0370d57353ac",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10b767a1-31d3-4067-8b57-99e92557685e",
   "metadata": {},
   "source": [
    "### For any multi-batch cases, use applybatch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a192fe-1a85-403a-ab25-901a545b42cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "applybatch?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156d8d75-ca67-4b9e-a207-70874ec2a3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 1 audio_file, n text_targets\n",
    "# description_source as List[str] or str of words\n",
    "\n",
    "# description_source as str / path to words.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6c8813-1672-47c3-a5ef-c8ad19fe1b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### n audio_files, 1 text_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c4093a-a131-47e5-92d3-a39b4986c12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### n audio_files, n_text_targets\n",
    "# description_source as List[str] or str of words\n",
    "\n",
    "# description_source as str / path to words.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851fac92-ad9c-4227-bea4-3181a0325000",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fx2fx",
   "language": "python",
   "name": "fx2fx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
